{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heart_sound_github.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOlB0j3qo7dmqjZAhd96GPD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripathy12345/resume/blob/main/heart_sound_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvEZh-54zN0c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_iviFm5zcDw"
      },
      "source": [
        "!pip3 install autokeras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irt1U6RA0S1_"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYc5q8qD0fDf"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import PIL\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import autokeras as ak\n",
        "import tensorflow\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWv9vmaK0pL_"
      },
      "source": [
        "import numpy as np\n",
        "#x = np.load('/content/drive/MyDrive/PCG_signal_time_frequency_image/github_database_5Class_complete/classification_scheme1/scheme1_x.npy')\n",
        "#y = np.load('/content/drive/MyDrive/PCG_signal_time_frequency_image/github_database_5Class_complete/classification_scheme1/scheme1_y.npy')\n",
        "\n",
        "x = np.load('/content/drive/MyDrive/PCG_signal_time_frequency_image/github_database_5Class_complete/classification_scheme2/scheme2_x.npy')\n",
        "y = np.load('/content/drive/MyDrive/PCG_signal_time_frequency_image/github_database_5Class_complete/classification_scheme2/scheme2_y.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5kZusIPrQHT"
      },
      "source": [
        "test_acc_list = []\n",
        "K_cappa_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "F1_list = []\n",
        "\n",
        "for iter in range(5):\n",
        "  print(\"Trial Number : \", (iter+1))\n",
        "  loaded_model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/PCG_signal_time_frequency_image/model_autokeras\", custom_objects=ak.CUSTOM_OBJECTS)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=1/8, random_state=1)\n",
        "\n",
        "\n",
        "  y_tr_one_hot  = np.zeros((np.array(y_train).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_train).shape[0]):\n",
        "    label = y_train[i]\n",
        "    y_tr_one_hot[i][int(label)] = 1\n",
        "  K.clear_session()\n",
        "  \n",
        "#clf = ak.ImageClassifier(overwrite=True, max_trials=4)\n",
        "#clf.fit(x_train, y_tr_one_hot,epochs=40)\n",
        "#results = clf.predict(x_test)\n",
        "#model = clf.export_model()\n",
        "#model.save(\"/content/drive/MyDrive/PCG_signal_time_frequency_image/model_autokeras\", save_format=\"tf\")\n",
        "#print(model.summary())\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "  loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  y_val_one_hot  = np.zeros((np.array(y_val).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_val).shape[0]):\n",
        "    label = y_val[i]\n",
        "    y_val_one_hot[i][int(label)] = 1\n",
        "\n",
        "  hist = loaded_model.fit(np.array(x_train), y_tr_one_hot, validation_data=(np.array(x_val), y_val_one_hot),batch_size=128, epochs=10,verbose=0)\n",
        "\n",
        "  y_te_one_hot  = np.zeros((np.array(y_test).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_test).shape[0]):\n",
        "    label = y_test[i]\n",
        "    y_te_one_hot[i][int(label)] = 1\n",
        "\n",
        "  test_loss, test_acc = loaded_model.evaluate(np.array(x_test), np.array(y_te_one_hot), verbose=0)\n",
        "  print('Accuracy:',test_acc)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  ##Evaluating Sensitivity, Accuracy and Kappa scores\n",
        "  y_prob = loaded_model.predict(x_test) \n",
        "  Y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "  K_cappa = sklearn.metrics.cohen_kappa_score(y_test,Y_pred)\n",
        "  print(\"cohen kappa scores:\" ,K_cappa)\n",
        "  K_cappa_list.append(K_cappa)\n",
        "\n",
        "  cm1 = confusion_matrix(y_test,Y_pred)\n",
        "  print(\"confusion matrix \\n\",cm1)\n",
        "\n",
        "  precision = sklearn.metrics.precision_score(y_test,Y_pred,average='micro')\n",
        "  print('precision : ', precision)\n",
        "  precision_list.append(precision)\n",
        "\n",
        "  recall = sklearn.metrics.recall_score(y_test,Y_pred,average='micro')\n",
        "  print('recall : ', recall)\n",
        "  recall_list.append(recall)\n",
        "\n",
        "  F1 = sklearn.metrics.f1_score(y_test,Y_pred,average=\"micro\")\n",
        "  print(\"F1 : \", F1)\n",
        "  F1_list.append(F1)\n",
        "\n",
        "\n",
        "print('5-Trial Accuracy:',sum(test_acc_list)/len(test_acc_list))\n",
        "print(\"5-Trial cohen kappa scores:\" ,sum(K_cappa_list)/len(K_cappa_list))\n",
        "print('5-Trial precision : ', sum(precision_list)/len(precision_list))\n",
        "print('5-Trial recall : ', sum(recall_list)/len(recall_list))\n",
        "print(\"5-Trial F1 : \", sum(F1_list)/len(F1_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fj-b5dguDSj"
      },
      "source": [
        "test_acc_list = []\n",
        "K_cappa_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "F1_list = []\n",
        "\n",
        "for iter in range(5):\n",
        "  print(\"Trial Number : \", (iter+1))\n",
        "  train_ratio=0.70\n",
        "  validation_ratio=0.10\n",
        "  test_ratio=0.20\n",
        "  loaded_model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/PCG_signal_time_frequency_image/model_autokeras\", custom_objects=ak.CUSTOM_OBJECTS)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=1)\n",
        "  x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=1)\n",
        "\n",
        "\n",
        "  y_tr_one_hot  = np.zeros((np.array(y_train).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_train).shape[0]):\n",
        "    label = y_train[i]\n",
        "    y_tr_one_hot[i][int(label)] = 1\n",
        "\n",
        "  K.clear_session()\n",
        "  #modelf = model_define()\n",
        "\n",
        "  #print(modelf.summary())\n",
        "  optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "  loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  y_val_one_hot  = np.zeros((np.array(y_val).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_val).shape[0]):\n",
        "    label = y_val[i]\n",
        "    y_val_one_hot[i][int(label)] = 1\n",
        "\n",
        "  hist = loaded_model.fit(np.array(x_train), y_tr_one_hot, validation_data=(np.array(x_val), y_val_one_hot),batch_size=128, epochs=10,verbose=0)\n",
        "\n",
        "  y_te_one_hot  = np.zeros((np.array(y_test).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_test).shape[0]):\n",
        "    label = y_test[i]\n",
        "    y_te_one_hot[i][int(label)] = 1\n",
        "\n",
        "  test_loss, test_acc = loaded_model.evaluate(np.array(x_test), np.array(y_te_one_hot), verbose=0)\n",
        "  print('Accuracy:',test_acc)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  ##Evaluating Sensitivity, Accuracy and Kappa scores\n",
        "  y_prob = loaded_model.predict(x_test) \n",
        "  Y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "  K_cappa = sklearn.metrics.cohen_kappa_score(y_test,Y_pred)\n",
        "  print(\"cohen kappa scores:\" ,K_cappa)\n",
        "  K_cappa_list.append(K_cappa)\n",
        "\n",
        "  cm1 = confusion_matrix(y_test,Y_pred)\n",
        "  print(\"confusion matrix \\n\",cm1)\n",
        "\n",
        "  precision = sklearn.metrics.precision_score(y_test,Y_pred,average='micro')\n",
        "  print('precision : ', precision)\n",
        "  precision_list.append(precision)\n",
        "\n",
        "  recall = sklearn.metrics.recall_score(y_test,Y_pred,average='micro')\n",
        "  print('recall : ', recall)\n",
        "  recall_list.append(recall)\n",
        "\n",
        "  F1 = sklearn.metrics.f1_score(y_test,Y_pred,average=\"micro\")\n",
        "  print(\"F1 : \", F1)\n",
        "  F1_list.append(F1)\n",
        "\n",
        "\n",
        "print('5-Trial Accuracy:',sum(test_acc_list)/len(test_acc_list))\n",
        "print(\"5-Trial cohen kappa scores:\" ,sum(K_cappa_list)/len(K_cappa_list))\n",
        "print('5-Trial precision : ', sum(precision_list)/len(precision_list))\n",
        "print('5-Trial recall : ', sum(recall_list)/len(recall_list))\n",
        "print(\"5-Trial F1 : \", sum(F1_list)/len(F1_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-cm6CHawlfD"
      },
      "source": [
        "test_acc_list = []\n",
        "K_cappa_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "F1_list = []\n",
        "\n",
        "for iter in range(5):\n",
        "  print(\"Trial Number : \", (iter+1))\n",
        "  train_ratio=0.60\n",
        "  validation_ratio=0.20\n",
        "  test_ratio=0.20\n",
        "  loaded_model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/PCG_signal_time_frequency_image/model_autokeras\", custom_objects=ak.CUSTOM_OBJECTS)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=1)\n",
        "  x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=1)\n",
        "\n",
        "\n",
        "  y_tr_one_hot  = np.zeros((np.array(y_train).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_train).shape[0]):\n",
        "    label = y_train[i]\n",
        "    y_tr_one_hot[i][int(label)] = 1\n",
        "\n",
        "  K.clear_session()\n",
        "  #modelf = model_define()\n",
        "\n",
        "  #print(modelf.summary())\n",
        "  optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "  loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  y_val_one_hot  = np.zeros((np.array(y_val).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_val).shape[0]):\n",
        "    label = y_val[i]\n",
        "    y_val_one_hot[i][int(label)] = 1\n",
        "\n",
        "  hist = loaded_model.fit(np.array(x_train), y_tr_one_hot, validation_data=(np.array(x_val), y_val_one_hot),batch_size=128, epochs=10,verbose=0)\n",
        "\n",
        "  y_te_one_hot  = np.zeros((np.array(y_test).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_test).shape[0]):\n",
        "    label = y_test[i]\n",
        "    y_te_one_hot[i][int(label)] = 1\n",
        "\n",
        "  test_loss, test_acc = loaded_model.evaluate(np.array(x_test), np.array(y_te_one_hot), verbose=0)\n",
        "  print('Accuracy:',test_acc)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  ##Evaluating Sensitivity, Accuracy and Kappa scores\n",
        "  y_prob = loaded_model.predict(x_test) \n",
        "  Y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "  K_cappa = sklearn.metrics.cohen_kappa_score(y_test,Y_pred)\n",
        "  print(\"cohen kappa scores:\" ,K_cappa)\n",
        "  K_cappa_list.append(K_cappa)\n",
        "\n",
        "  cm1 = confusion_matrix(y_test,Y_pred)\n",
        "  print(\"confusion matrix \\n\",cm1)\n",
        "\n",
        "  precision = sklearn.metrics.precision_score(y_test,Y_pred,average='micro')\n",
        "  print('precision : ', precision)\n",
        "  precision_list.append(precision)\n",
        "\n",
        "  recall = sklearn.metrics.recall_score(y_test,Y_pred,average='micro')\n",
        "  print('recall : ', recall)\n",
        "  recall_list.append(recall)\n",
        "\n",
        "  F1 = sklearn.metrics.f1_score(y_test,Y_pred,average=\"micro\")\n",
        "  print(\"F1 : \", F1)\n",
        "  F1_list.append(F1)\n",
        "\n",
        "\n",
        "print('5-Trial Accuracy:',sum(test_acc_list)/len(test_acc_list))\n",
        "print(\"5-Trial cohen kappa scores:\" ,sum(K_cappa_list)/len(K_cappa_list))\n",
        "print('5-Trial precision : ', sum(precision_list)/len(precision_list))\n",
        "print('5-Trial recall : ', sum(recall_list)/len(recall_list))\n",
        "print(\"5-Trial F1 : \", sum(F1_list)/len(F1_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_eMZgg5wqPx"
      },
      "source": [
        "test_acc_list = []\n",
        "K_cappa_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "F1_list = []\n",
        "\n",
        "for iter in range(5):\n",
        "  print(\"Trial Number : \", (iter+1))\n",
        "  train_ratio=0.75\n",
        "  validation_ratio=0.15\n",
        "  test_ratio=0.20\n",
        "  loaded_model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/PCG_signal_time_frequency_image/model_autokeras\", custom_objects=ak.CUSTOM_OBJECTS)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=1)\n",
        "  x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=1)\n",
        "\n",
        "\n",
        "  y_tr_one_hot  = np.zeros((np.array(y_train).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_train).shape[0]):\n",
        "    label = y_train[i]\n",
        "    y_tr_one_hot[i][int(label)] = 1\n",
        "\n",
        "  K.clear_session()\n",
        "  #modelf = model_define()\n",
        "\n",
        "  #print(modelf.summary())\n",
        "  optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "  loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  y_val_one_hot  = np.zeros((np.array(y_val).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_val).shape[0]):\n",
        "    label = y_val[i]\n",
        "    y_val_one_hot[i][int(label)] = 1\n",
        "\n",
        "  hist = loaded_model.fit(np.array(x_train), y_tr_one_hot, validation_data=(np.array(x_val), y_val_one_hot),batch_size=128, epochs=10,verbose=0)\n",
        "\n",
        "  y_te_one_hot  = np.zeros((np.array(y_test).shape[0],5))\n",
        "\n",
        "  for i in range(np.array(y_test).shape[0]):\n",
        "    label = y_test[i]\n",
        "    y_te_one_hot[i][int(label)] = 1\n",
        "\n",
        "  test_loss, test_acc = loaded_model.evaluate(np.array(x_test), np.array(y_te_one_hot), verbose=0)\n",
        "  print('Accuracy:',test_acc)\n",
        "  test_acc_list.append(test_acc)\n",
        "\n",
        "  ##Evaluating Sensitivity, Accuracy and Kappa scores\n",
        "  y_prob = loaded_model.predict(x_test) \n",
        "  Y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "  K_cappa = sklearn.metrics.cohen_kappa_score(y_test,Y_pred)\n",
        "  print(\"cohen kappa scores:\" ,K_cappa)\n",
        "  K_cappa_list.append(K_cappa)\n",
        "\n",
        "  cm1 = confusion_matrix(y_test,Y_pred)\n",
        "  print(\"confusion matrix \\n\",cm1)\n",
        "\n",
        "  precision = sklearn.metrics.precision_score(y_test,Y_pred,average='micro')\n",
        "  print('precision : ', precision)\n",
        "  precision_list.append(precision)\n",
        "\n",
        "  recall = sklearn.metrics.recall_score(y_test,Y_pred,average='micro')\n",
        "  print('recall : ', recall)\n",
        "  recall_list.append(recall)\n",
        "\n",
        "  F1 = sklearn.metrics.f1_score(y_test,Y_pred,average=\"micro\")\n",
        "  print(\"F1 : \", F1)\n",
        "  F1_list.append(F1)\n",
        "\n",
        "\n",
        "print('5-Trial Accuracy:',sum(test_acc_list)/len(test_acc_list))\n",
        "print(\"5-Trial cohen kappa scores:\" ,sum(K_cappa_list)/len(K_cappa_list))\n",
        "print('5-Trial precision : ', sum(precision_list)/len(precision_list))\n",
        "print('5-Trial recall : ', sum(recall_list)/len(recall_list))\n",
        "print(\"5-Trial F1 : \", sum(F1_list)/len(F1_list))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}